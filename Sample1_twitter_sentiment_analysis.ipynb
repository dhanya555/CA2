{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c681b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from nltk>=3.1->textblob) (4.63.0)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\\\programdata\\\\anaconda3\\\\envs\\\\edadataprep\\\\lib\\\\site-packages\\\\numpy-1.22.3.dist-info\\\\METADATA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.8.0-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Installing collected packages: tweepy\n",
      "Successfully installed tweepy-4.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\\\programdata\\\\anaconda3\\\\envs\\\\edadataprep\\\\lib\\\\site-packages\\\\numpy-1.22.3.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "# Install Libraries\n",
    "!pip install textblob\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f49768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycountry\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from pycountry) (58.0.4)\n",
      "Building wheels for collected packages: pycountry\n",
      "  Building wheel for pycountry (PEP 517): started\n",
      "  Building wheel for pycountry (PEP 517): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=580c486e4498b348241499628c4139384df0b29bd090c2538d77d86cdfeecee4\n",
      "  Stored in directory: c:\\users\\dhany\\appdata\\local\\pip\\cache\\wheels\\47\\15\\92\\e6dc85fcb0686c82e1edbcfdf80cfe4808c058813fed0baa8f\n",
      "Successfully built pycountry\n",
      "Installing collected packages: pycountry\n",
      "Successfully installed pycountry-22.3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\\\programdata\\\\anaconda3\\\\envs\\\\edadataprep\\\\lib\\\\site-packages\\\\numpy-1.22.3.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df2ef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\edadataprep\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993246 sha256=ad274442fb63f04b11ca28ee7d5a993c86ad474bb6346422f2989a71b9d31f6c\n",
      "  Stored in directory: c:\\users\\dhany\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\\\programdata\\\\anaconda3\\\\envs\\\\edadataprep\\\\lib\\\\site-packages\\\\numpy-1.22.3.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8a091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbb03979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "consumerKey = \"dlmSwyiJRNgL5a5y7tD0Zjxgr\"\n",
    "consumerSecret = \"tMxnFrRs1088cqIjlDnaG4RUT9xs1AXd3Mpwvv3TNaUxUsnx0D\"\n",
    "accessToken = \"1518310189962780672-fpocSf7XDjjl3LctVad2pCDEXnoF0a\"\n",
    "accessTokenSecret = \"GWYlpl3UuYg4TQ003BeL3FIqpDsV9jptyPRenF0PuGGr2\"\n",
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aa2b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter keyword or hashtag to search: lockdown2 london\n",
      "Please enter how many tweets to analyze: 2500\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "\n",
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole) \n",
    "\n",
    "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "noOfTweet = int(input (\"Please enter how many tweets to analyze: \"))\n",
    "\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(noOfTweet)\n",
    "positive  = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    \n",
    "    #print(tweet.text)\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    \n",
    "    if neg > pos:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "\n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    "    \n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1\n",
    "\n",
    "positive = percentage(positive, noOfTweet)\n",
    "negative = percentage(negative, noOfTweet)\n",
    "neutral = percentage(neutral, noOfTweet)\n",
    "polarity = percentage(polarity, noOfTweet)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c124788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number:  0\n",
      "positive number:  0\n",
      "negative number:  0\n",
      "neutral number:  0\n"
     ]
    }
   ],
   "source": [
    "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "print(\"positive number: \",len(positive_list))\n",
    "print(\"negative number: \", len(negative_list))\n",
    "print(\"neutral number: \",len(neutral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2678bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab630d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
